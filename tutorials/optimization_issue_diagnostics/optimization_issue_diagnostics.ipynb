{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Data for Optimization Help Issues\n",
        "\n",
        "This notebook helps you export the information needed to file an [Optimization Help](https://github.com/meta-pytorch/botorch/issues/new?template=optimization_help.yml) issue on BoTorch.\n",
        "\n",
        "You'll use the `get_data_for_optimization_help` helper function to export `optimization_help_data.json`, which contains the training data and model state dict. Ideally, this file would be saved as close to the error-causing part of the code as possible, or at the end of optimization in case of bad performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 260120 20:28:20 2584013286:10] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n"
          ]
        }
      ],
      "source": [
        "# Replace these with your actual data and model\n",
        "# train_X: (n, d) tensor of inputs\n",
        "# train_Y: (n, m) tensor of outputs\n",
        "# model: your fitted BoTorch model\n",
        "\n",
        "# Example (delete this and use your own):\n",
        "from botorch.models import SingleTaskGP\n",
        "train_X = torch.rand(10, 2)\n",
        "train_Y = torch.sin(train_X.sum(dim=-1, keepdim=True))\n",
        "model = SingleTaskGP(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'get_data_for_optimization_help' from 'botorch.models.utils' (/var/svcscm/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/models/utils/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n",
            "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Export training data and model state dict to JSON\u001b[39;00m\n",
            "\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_data_for_optimization_help\n",
            "\u001b[1;32m      4\u001b[0m get_data_for_optimization_help(model)\n",
            "\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved optimization_help_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_data_for_optimization_help' from 'botorch.models.utils' (/var/svcscm/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/models/utils/__init__.py)"
          ]
        },
        {
          "data": {
            "application/notebook-debug-button": "{\n\t\"notebookUri\": \"file:///data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/tutorials/optimization_issue_diagnostics/optimization_issue_diagnostics.ipynb\"\n}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Export training data and model state dict to JSON\n",
        "from botorch.models.utils import get_data_for_optimization_help\n",
        "\n",
        "get_data_for_optimization_help(model)\n",
        "print(\"Saved optimization_help_data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Done!** Attach `optimization_help_data.json` to your [Optimization Help issue](https://github.com/meta-pytorch/botorch/issues/new?template=optimization_help.yml)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appendix: Example Issue\n",
        "\n",
        "Below is an example of a common issue where a user forgot to use an input transform to scale the inputs to the unit cube, causing the GP to be poorly conditioned. The comments marked with `>>> EXTRACT HERE <<<` show where you should (ideally) call `get_data_for_optimization_help(model)` for filing an issue.\n",
        "\n",
        "\n",
        "This cell will intentionally error out with a numerical optimization issue. The correct setup is given by uncommenting the `input_transform` and re-initializing the model with the input transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 260120 14:05:37 1214446538:43] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n",
            "[W 260120 14:05:37 assorted:271] Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "[W 260120 14:05:37 1214446538:43] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n",
            "[W 260120 14:05:37 assorted:271] Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "[W 260120 14:05:37 fit:212] `scipy_minimize` terminated with status OptimizationStatus.FAILURE, displaying original message from `scipy.optimize.minimize`: ABNORMAL: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/50, best_f: -948942.3750\n",
            "Iteration 2/50, best_f: -933277.6875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 260120 14:05:37 1214446538:43] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n",
            "[W 260120 14:05:37 assorted:271] Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "[W 260120 14:05:37 fit:212] `scipy_minimize` terminated with status OptimizationStatus.FAILURE, displaying original message from `scipy.optimize.minimize`: ABNORMAL: \n",
            "[W 260120 14:05:37 1214446538:43] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n",
            "[W 260120 14:05:37 assorted:271] Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 3/50, best_f: -933277.6875\n",
            "Iteration 4/50, best_f: -933277.6875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 260120 14:05:37 1214446538:43] The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/meta-pytorch/botorch/discussions/1444\n",
            "[W 260120 14:05:37 assorted:271] Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "[W 260120 14:05:37 fit:212] `scipy_minimize` terminated with status OptimizationStatus.FAILURE, displaying original message from `scipy.optimize.minimize`: ABNORMAL: \n",
            "[W 260120 14:05:38 cholesky:40] A not p.d., added jitter of 1.0e-06 to the diagonal\n",
            "[W 260120 14:05:38 cholesky:40] A not p.d., added jitter of 1.0e-05 to the diagonal\n",
            "[W 260120 14:05:38 cholesky:40] A not p.d., added jitter of 1.0e-04 to the diagonal\n",
            "[W 260120 14:05:38 cholesky:40] A not p.d., added jitter of 1.0e-03 to the diagonal\n",
            "[W 260120 14:05:38 cholesky:40] A not p.d., added jitter of 1.0e-02 to the diagonal\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[40], line 67\u001b[0m\n",
            "\u001b[1;32m     64\u001b[0m acq_func \u001b[38;5;241m=\u001b[39m qLogExpectedImprovement(model\u001b[38;5;241m=\u001b[39mmodel, best_f\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(train_Y))\n",
            "\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Optimize acquisition function to get new candidates\u001b[39;00m\n",
            "\u001b[0;32m---> 67\u001b[0m candidates, _ \u001b[38;5;241m=\u001b[39m optimize_acqf\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m     68\u001b[0m     \u001b[49macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49macq_func\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m     69\u001b[0m     \u001b[49mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mbounds\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m     70\u001b[0m     \u001b[49mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mbatch_size\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m     71\u001b[0m     \u001b[49mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mnum_restarts\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m     72\u001b[0m     \u001b[49mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mraw_samples\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m     73\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Evaluate objective at new candidates\u001b[39;00m\n",
            "\u001b[1;32m     76\u001b[0m new_Y \u001b[38;5;241m=\u001b[39m your_objective(candidates)\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/optim/optimize.py:774\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, acq_function_sequence, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n",
            "\u001b[1;32m    747\u001b[0m     fixed_features \u001b[38;5;241m=\u001b[39m {\n",
            "\u001b[1;32m    748\u001b[0m         idx \u001b[38;5;241m%\u001b[39m bounds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]: val \u001b[38;5;28;01mfor\u001b[39;00m idx, val \u001b[38;5;129;01min\u001b[39;00m fixed_features\u001b[38;5;241m.\u001b[39mitems()\n",
            "\u001b[1;32m    749\u001b[0m     }\n",
            "\u001b[1;32m    751\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n",
            "\u001b[1;32m    752\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n",
            "\u001b[1;32m    753\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    772\u001b[0m     acq_function_sequence\u001b[38;5;241m=\u001b[39macq_function_sequence,\n",
            "\u001b[1;32m    773\u001b[0m )\n",
            "\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf\u001b[49m(\u001b[49mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_acqf_inputs\u001b[49m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/optim/optimize.py:795\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n",
            "\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n",
            "\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n",
            "\u001b[0;32m--> 795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_batch\u001b[49m(\u001b[49mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/optim/optimize.py:362\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n",
            "\u001b[1;32m    357\u001b[0m     required_num_restarts \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m provided_initial_conditions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mraw_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m required_num_restarts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument ``acq_function``\u001b[39;00m\n",
            "\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# to anonymous call.\u001b[39;00m\n",
            "\u001b[0;32m--> 362\u001b[0m     generated_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mget_ic_generator\u001b[49m(\u001b[49m)\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m    363\u001b[0m         \u001b[49macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49macq_function\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    364\u001b[0m         \u001b[49mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mbounds\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    365\u001b[0m         \u001b[49mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mq\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    366\u001b[0m         \u001b[49mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mrequired_num_restarts\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    367\u001b[0m         \u001b[49mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mraw_samples\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    368\u001b[0m         \u001b[49mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mfixed_features\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    369\u001b[0m         \u001b[49moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49moptions\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    370\u001b[0m         \u001b[49minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49minequality_constraints\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    371\u001b[0m         \u001b[49mequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mequality_constraints\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    372\u001b[0m         \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mic_gen_kwargs\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    373\u001b[0m     \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m    375\u001b[0m batch_initial_conditions \u001b[38;5;241m=\u001b[39m _combine_initial_conditions(\n",
            "\u001b[1;32m    376\u001b[0m     provided_initial_conditions\u001b[38;5;241m=\u001b[39mprovided_initial_conditions,\n",
            "\u001b[1;32m    377\u001b[0m     generated_initial_conditions\u001b[38;5;241m=\u001b[39mgenerated_initial_conditions,\n",
            "\u001b[1;32m    378\u001b[0m )\n",
            "\u001b[1;32m    380\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n",
            "\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
            "\u001b[1;32m    382\u001b[0m     (\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    386\u001b[0m     ),\n",
            "\u001b[1;32m    387\u001b[0m )\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/optim/initializers.py:450\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator, fixed_X_fantasies)\u001b[0m\n",
            "\u001b[1;32m    441\u001b[0m     acq_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n",
            "\u001b[1;32m    442\u001b[0m         [\n",
            "\u001b[1;32m    443\u001b[0m             acq_function(x_\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mcpu()\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    446\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n",
            "\u001b[1;32m    447\u001b[0m     )\n",
            "\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Downselect the initial conditions based on the acquisition function values\u001b[39;00m\n",
            "\u001b[0;32m--> 450\u001b[0m batch_initial_conditions, _ \u001b[38;5;241m=\u001b[39m init_func\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m    451\u001b[0m     \u001b[49mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mX_rnd\u001b[49m,\u001b[49m \u001b[49macq_vals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49macq_vals\u001b[49m,\u001b[49m \u001b[49mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mnum_restarts\u001b[49m,\u001b[49m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49minit_kwargs\u001b[49m\n",
            "\u001b[1;32m    452\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m    453\u001b[0m batch_initial_conditions \u001b[38;5;241m=\u001b[39m batch_initial_conditions\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Return the initial conditions if no warnings were raised\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/optim/initializers.py:1005\u001b[0m, in \u001b[0;36minitialize_q_batch\u001b[0;34m(X, acq_vals, n, eta)\u001b[0m\n",
            "\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X[idcs], acq_vals[idcs]\n",
            "\u001b[1;32m   1004\u001b[0m max_val, max_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(acq_vals, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[0;32m-> 1005\u001b[0m idcs \u001b[38;5;241m=\u001b[39m boltzmann_sample\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m   1006\u001b[0m     \u001b[49macq_vals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mpermute\u001b[49m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m,\u001b[49m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m(\u001b[49mbatch_shape\u001b[49m)\u001b[49m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m)\u001b[49m,\u001b[49m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m)\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   1007\u001b[0m     \u001b[49mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mn\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   1008\u001b[0m     \u001b[49meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49meta\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m   1009\u001b[0m \u001b[49m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_shape)))\n",
            "\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# make sure we get the maximum\u001b[39;00m\n",
            "\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_shape \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize():\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/utils/sampling.py:1111\u001b[0m, in \u001b[0;36mboltzmann_sample\u001b[0;34m(function_values, num_samples, eta, replacement, temp_decrease)\u001b[0m\n",
            "\u001b[1;32m   1108\u001b[0m     eta \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m temp_decrease\n",
            "\u001b[1;32m   1109\u001b[0m     weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(eta \u001b[38;5;241m*\u001b[39m norm_weights)\n",
            "\u001b[0;32m-> 1111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batched_multinomial\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m   1112\u001b[0m     \u001b[49mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mweights\u001b[49m,\u001b[49m \u001b[49mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mnum_samples\u001b[49m,\u001b[49m \u001b[49mreplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mreplacement\u001b[49m\n",
            "\u001b[1;32m   1113\u001b[0m \u001b[49m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/.bento/kernels/bento_kernel_ae/5847/bento_kernel_ae_binary-inplace#link-tree/botorch/utils/sampling.py:351\u001b[0m, in \u001b[0;36mbatched_multinomial\u001b[0;34m(weights, num_samples, replacement, generator, out)\u001b[0m\n",
            "\u001b[1;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sample from multinomial with an arbitrary number of batch dimensions.\u001b[39;00m\n",
            "\u001b[1;32m    325\u001b[0m \n",
            "\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    >>> samples = batched_multinomial(weights, 4)  # shape is 2 x 3 x 4\u001b[39;00m\n",
            "\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    350\u001b[0m batch_shape, n_categories \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], weights\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[0;32m--> 351\u001b[0m flat_samples \u001b[38;5;241m=\u001b[39m torch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mmultinomial\u001b[49m(\u001b[49m\n",
            "\u001b[1;32m    352\u001b[0m     \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mview\u001b[49m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m,\u001b[49m \u001b[49mn_categories\u001b[49m)\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    353\u001b[0m     \u001b[49mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mnum_samples\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    354\u001b[0m     \u001b[49mreplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mreplacement\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    355\u001b[0m     \u001b[49mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49mgenerator\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    356\u001b[0m     \u001b[49mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m \u001b[49mout\u001b[49m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m \u001b[49mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49mview\u001b[49m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m,\u001b[49m \u001b[49mnum_samples\u001b[49m)\u001b[49m,\u001b[49m\n",
            "\u001b[1;32m    357\u001b[0m \u001b[49m)\u001b[49m\n",
            "\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flat_samples\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, num_samples)\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
          ]
        },
        {
          "data": {
            "application/notebook-debug-button": "{\n\t\"notebookUri\": \"file:///data/sandcastle/boxes/fbsource/fbcode/pytorch/botorch/tutorials/optimization_issue_diagnostics/optimization_issue_diagnostics.ipynb\"\n}"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from botorch.models.transforms.input import Normalize\n",
        "import torch\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.acquisition import qLogExpectedImprovement\n",
        "from botorch.optim import optimize_acqf\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.models.utils import get_data_for_optimization_help\n",
        "\n",
        "# --- User-defined parameters and objective ---\n",
        "\n",
        "NUM_INIT = 11\n",
        "NUM_ITERATIONS = 50\n",
        "batch_size = 1\n",
        "num_restarts = 4\n",
        "raw_samples = 1024\n",
        "\n",
        "# Define bounds here - The bounds here are intentionally set to be extreme -\n",
        "# one small and one large. If inputs are not scaled to be in [0, 1], this will\n",
        "# cause numerical issues downstream.\n",
        "bounds = torch.tensor([[-0.0001, -10000], [0.0001, 10000]])\n",
        "\n",
        "# we also need use float64 instead of float32. Setting it on the bounds is enough,\n",
        "# the change will be propagated to the X's, the Y's and the model.\n",
        "# bounds = bounds.to(torch.float64)\n",
        "input_transform=Normalize(d=train_X.shape[-1], bounds=bounds)\n",
        "\n",
        "# Dummy objective function for illustration\n",
        "def your_objective(X):\n",
        "    # Example: sum of squares (replace with your actual objective)\n",
        "    return -(X ** 2).sum(dim=-1, keepdim=True)\n",
        "\n",
        "# Generate initial data - TODO make sure your initial data is within these bounds\n",
        "train_X = draw_sobol_samples(n=NUM_INIT, bounds=bounds, q=1).squeeze(-2)\n",
        "train_Y = your_objective(train_X)\n",
        "\n",
        "# Optimization loop\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "    # ---------------------------------------------------------------------------\n",
        "    # Fit GP model\n",
        "    # NOTE: missing input_transform here causes issues, since the bounds are too\n",
        "    # extreme for the optimization to work.\n",
        "    model = SingleTaskGP(\n",
        "       train_X=train_X,\n",
        "       train_Y=train_Y,\n",
        "       # input_transform=input_transform\n",
        "    )\n",
        "    # ---------------------------------------------------------------------------\n",
        "\n",
        "    # ==========================================================================\n",
        "    # >>> EXTRACT DATA FOR OPTIMIZATION HELP HERE <<<\n",
        "    # Since the error will occur in one of the lines below,\n",
        "    # this is where you should save your data for the Optimization Help issue.\n",
        "    # This saves train_X, train_Y, and model.state_dict() to a single JSON file.\n",
        "    get_data_for_optimization_help(model)\n",
        "    # ==========================================================================\n",
        "\n",
        "\n",
        "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "    fit_gpytorch_mll(mll)\n",
        "\n",
        "    # Build acquisition function\n",
        "    acq_func = qLogExpectedImprovement(model=model, best_f=torch.max(train_Y))\n",
        "\n",
        "    # Optimize acquisition function to get new candidates\n",
        "    candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=bounds,\n",
        "        q=batch_size,\n",
        "        num_restarts=num_restarts,\n",
        "        raw_samples=raw_samples,\n",
        "    )\n",
        "\n",
        "    # Evaluate objective at new candidates\n",
        "    new_Y = your_objective(candidates)\n",
        "\n",
        "    # Update training data\n",
        "    train_X = torch.cat([train_X, candidates], dim=0)\n",
        "    train_Y = torch.cat([train_Y, new_Y], dim=0)\n",
        "\n",
        "    print(f\"Iteration {iteration + 1}/{NUM_ITERATIONS}, best_f: {train_Y.max().item():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "5d1c0dac-b3f5-4593-866d-fd1dad4d9d0b",
    "isAdHoc": false,
    "language_info": {
      "name": "plaintext"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
